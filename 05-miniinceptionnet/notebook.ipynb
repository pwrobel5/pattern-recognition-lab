{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRO - NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8S0V5Fn-Hna"
      },
      "source": [
        "# Funkcje definiujące model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IAXnPsH-L4h"
      },
      "source": [
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "\n",
        "X5_PERCENT = 0.2\n",
        "\n",
        "\n",
        "def mini_inception_net(width, height, depth, classes, use_dropout=True, separable_convolutions=False, use_5x5=False,\n",
        "                       use_gap=False):\n",
        "    def conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "        if separable_convolutions:\n",
        "            x = layers.SeparableConv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "        else:\n",
        "            x = layers.Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "        x = layers.BatchNormalization(axis=chanDim)(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "        if use_5x5:\n",
        "            num_sum = numK1x1 + numK3x3\n",
        "            numK5x5 = round(X5_PERCENT * num_sum)\n",
        "            numK1x1 = round((1 - X5_PERCENT) * numK1x1)\n",
        "            numK3x3 = num_sum - numK5x5 - numK1x1  # to keep filters number constant\n",
        "\n",
        "            conv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "            conv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "            conv_5x5 = conv_module(x, numK5x5, 5, 5, (1, 1), chanDim)\n",
        "            x = layers.concatenate([conv_1x1, conv_3x3, conv_5x5], axis=chanDim)\n",
        "        else:\n",
        "            conv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "            conv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "            x = layers.concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def downsample_module(x, K, chanDim):\n",
        "        conv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim, padding=\"valid\")\n",
        "        pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "        x = layers.concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\n",
        "        return x\n",
        "\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "\n",
        "    # define the model input and first CONV module\n",
        "    inputs = layers.Input(shape=inputShape)\n",
        "    x = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\n",
        "    # two Inception modules followed by a downsample module\n",
        "    x = inception_module(x, 32, 32, chanDim)\n",
        "    x = inception_module(x, 32, 48, chanDim)\n",
        "    x = downsample_module(x, 80, chanDim)\n",
        "\n",
        "    # four Inception modules followed by a downsample module\n",
        "    x = inception_module(x, 112, 48, chanDim)\n",
        "    x = inception_module(x, 96, 64, chanDim)\n",
        "    x = inception_module(x, 80, 80, chanDim)\n",
        "    x = inception_module(x, 48, 96, chanDim)\n",
        "    x = downsample_module(x, 96, chanDim)\n",
        "\n",
        "    # two Inception modules followed by global POOL and dropout\n",
        "    x = inception_module(x, 176, 160, chanDim)\n",
        "    x = inception_module(x, 176, 160, chanDim)\n",
        "    if use_gap:\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "    else:\n",
        "        x = layers.AveragePooling2D((7, 7))(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # softmax classifier\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(classes)(x)\n",
        "    x = layers.Activation(\"softmax\")(x)\n",
        "\n",
        "    # create the model\n",
        "    model = models.Model(inputs, x, name=\"miniinceptionnet\")\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8ncT-m-T8F"
      },
      "source": [
        "# Trenowanie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vLGkZE1-XAU"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "from statistics import mean\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.callbacks import Callback"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhLzR-z-hO3"
      },
      "source": [
        "INIT_LR = 1e-2\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 60\n",
        "LABEL_NAMES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5-FGK6w-jxZ"
      },
      "source": [
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTB6qLp5-mlo"
      },
      "source": [
        "def train_model(model, output_suffix):\n",
        "    print(\"[INFO] loading CIFAR-10 dataset...\")\n",
        "    ((train_x, train_y), (test_x, test_y)) = cifar10.load_data()\n",
        "\n",
        "    # scale the data to the range [0, 1]\n",
        "    train_x = train_x.astype(\"float32\") / 255.0\n",
        "    test_x = test_x.astype(\"float32\") / 255.0\n",
        "\n",
        "    # convert the labels from integers to vectors\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    train_y = label_binarizer.fit_transform(train_y)\n",
        "    test_y = label_binarizer.fit_transform(test_y)\n",
        "\n",
        "    # construct the image generator for data augmentation\n",
        "    augmenter = ImageDataGenerator(rotation_range=18, zoom_range=0.15,\n",
        "                                   width_shift_range=0.2, height_shift_range=-.2, shear_range=0.15,\n",
        "                                   horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "    # initialize the optimizer and compile the model\n",
        "    optimizer = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "    print(\"[INFO] training network...\")\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "    # train the network\n",
        "    time_callback = TimeHistory()\n",
        "    history = model.fit_generator(\n",
        "        augmenter.flow(train_x, train_y, batch_size=BATCH_SIZE),\n",
        "        validation_data=(test_x, test_y),\n",
        "        steps_per_epoch=train_x.shape[0] // BATCH_SIZE,\n",
        "        epochs=NUM_EPOCHS,\n",
        "        verbose=1,\n",
        "        callbacks=[time_callback]\n",
        "    )\n",
        "\n",
        "    # save model\n",
        "    model.save(\"miniinception_{}\".format(output_suffix))\n",
        "\n",
        "    # evaluate the network\n",
        "    print(\"[INFO] evaluating network...\")\n",
        "    predictions = model.predict(test_x, batch_size=BATCH_SIZE)\n",
        "    print(classification_report(test_y.argmax(axis=1),\n",
        "                                predictions.argmax(axis=1),\n",
        "                                target_names=LABEL_NAMES))\n",
        "\n",
        "    train_losses = history.history[\"loss\"]\n",
        "    val_losses = history.history[\"val_loss\"]\n",
        "    train_accuracies = history.history[\"accuracy\"]\n",
        "    val_accuracies = history.history[\"val_accuracy\"]\n",
        "    zipped_results = zip(train_losses, train_accuracies, val_losses, val_accuracies)\n",
        "\n",
        "    output_accuracy = open(\"accuracy_{}.txt\".format(output_suffix), \"w\")\n",
        "    for index, (train_loss, train_accuracy, val_loss, val_accuracy) in enumerate(zipped_results):\n",
        "        output_accuracy.write(\"{} {} {} {} {}\\n\".format(index + 1, train_loss, train_accuracy, val_loss, val_accuracy))\n",
        "    output_accuracy.close()\n",
        "\n",
        "    # determine the number of epochs and then construct the plot title\n",
        "    N = np.arange(0, NUM_EPOCHS)\n",
        "    title = \"Loss/Accuracy bez modyfikacji sieci\"\n",
        "\n",
        "    # plot the training loss and accuracy\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, history.history[\"loss\"], label=\"Loss (zbiór uczący)\")\n",
        "    plt.plot(N, history.history[\"val_loss\"], label=\"Loss (zbiór walidacyjny)\")\n",
        "    plt.plot(N, history.history[\"accuracy\"], label=\"Accuracy (zbiór uczący)\")\n",
        "    plt.plot(N, history.history[\"val_accuracy\"], label=\"Accuracy (zbiór walidacyjny)\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoka\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"miniinception_{}.png\".format(output_suffix))\n",
        "\n",
        "    average_epoch_time = mean(time_callback.times)\n",
        "    print(\"Average epoch training time: {} s\".format(average_epoch_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OrMR-aS-rQp",
        "outputId": "39906a9e-ce13-46ac-d6f3-9a7468367888"
      },
      "source": [
        "matplotlib.use(\"Agg\")\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
        "\n",
        "models = [\n",
        "    mini_inception_net(32, 32, 3, len(LABEL_NAMES)),\n",
        "    mini_inception_net(32, 32, 3, len(LABEL_NAMES), use_dropout=False),\n",
        "    mini_inception_net(32, 32, 3, len(LABEL_NAMES), separable_convolutions=True),\n",
        "    mini_inception_net(32, 32, 3, len(LABEL_NAMES), use_5x5=True),\n",
        "    mini_inception_net(None, None, 3, len(LABEL_NAMES), use_gap=True)\n",
        "]\n",
        "\n",
        "for index, model in enumerate(models):\n",
        "    train_model(model, str(index + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 dataset...\n",
            "[INFO] training network...\n",
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 96)   2688        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 96)   384         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 32)   3104        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 32)   27680       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 32)   128         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 32)   128         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 32)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 32)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 32, 32, 64)   0           activation_129[0][0]             \n",
            "                                                                 activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 32)   2080        concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 48)   27696       concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 32, 32, 32)   128         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 32, 32, 48)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 32)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 32, 32, 48)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 32, 32, 80)   0           activation_131[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 15, 15, 80)   57680       concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 15, 15, 80)   320         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 15, 15, 80)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 15, 15, 160)  0           activation_133[0][0]             \n",
            "                                                                 max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 15, 15, 112)  18032       concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 15, 15, 48)   69168       concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 15, 15, 112)  448         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 15, 15, 48)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 15, 15, 112)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 15, 15, 48)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 15, 15, 160)  0           activation_134[0][0]             \n",
            "                                                                 activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 15, 15, 96)   15456       concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 15, 15, 64)   92224       concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 15, 15, 96)   384         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 15, 15, 64)   256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 15, 15, 96)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 15, 15, 64)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 15, 15, 160)  0           activation_136[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 15, 15, 80)   12880       concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 15, 15, 80)   115280      concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 15, 15, 80)   320         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 15, 15, 80)   320         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 15, 15, 80)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 15, 15, 80)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 15, 15, 160)  0           activation_138[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 15, 15, 48)   7728        concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 15, 15, 96)   138336      concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 15, 15, 48)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 15, 15, 96)   384         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 15, 15, 48)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 15, 15, 96)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 15, 15, 144)  0           activation_140[0][0]             \n",
            "                                                                 activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 7, 7, 96)     124512      concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 96)     384         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 96)     0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 7, 7, 240)    0           activation_142[0][0]             \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 7, 7, 176)    42416       concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 7, 7, 160)    345760      concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 176)    704         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    640         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 176)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 7, 7, 336)    0           activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 176)    59312       concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 7, 7, 160)    484000      concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 176)    704         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    640         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 176)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 7, 7, 336)    0           activation_145[0][0]             \n",
            "                                                                 activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 336)    0           concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1, 1, 336)    0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 336)          0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           3370        flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 10)           0           dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,656,250\n",
            "Trainable params: 1,652,826\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.6319 - accuracy: 0.4043 - val_loss: 2.1758 - val_accuracy: 0.2759\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.2324 - accuracy: 0.5570 - val_loss: 1.4339 - val_accuracy: 0.5114\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0672 - accuracy: 0.6223 - val_loss: 1.6371 - val_accuracy: 0.4954\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9606 - accuracy: 0.6635 - val_loss: 1.0833 - val_accuracy: 0.6333\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.8803 - accuracy: 0.6947 - val_loss: 1.9772 - val_accuracy: 0.5007\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.8166 - accuracy: 0.7185 - val_loss: 1.0813 - val_accuracy: 0.6670\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.7604 - accuracy: 0.7370 - val_loss: 0.8826 - val_accuracy: 0.7103\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.7128 - accuracy: 0.7535 - val_loss: 0.9212 - val_accuracy: 0.7008\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.6807 - accuracy: 0.7660 - val_loss: 0.9525 - val_accuracy: 0.7057\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.6487 - accuracy: 0.7758 - val_loss: 0.8326 - val_accuracy: 0.7471\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.6176 - accuracy: 0.7877 - val_loss: 0.7329 - val_accuracy: 0.7615\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.5932 - accuracy: 0.7975 - val_loss: 0.7263 - val_accuracy: 0.7604\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.5685 - accuracy: 0.8058 - val_loss: 0.7528 - val_accuracy: 0.7591\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.5498 - accuracy: 0.8122 - val_loss: 0.7074 - val_accuracy: 0.7706\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.5287 - accuracy: 0.8199 - val_loss: 0.7115 - val_accuracy: 0.7903\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.5182 - accuracy: 0.8206 - val_loss: 1.1655 - val_accuracy: 0.7032\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.4982 - accuracy: 0.8330 - val_loss: 1.0305 - val_accuracy: 0.7372\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.4862 - accuracy: 0.8361 - val_loss: 0.6189 - val_accuracy: 0.8055\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.4738 - accuracy: 0.8383 - val_loss: 0.6049 - val_accuracy: 0.8113\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.4595 - accuracy: 0.8441 - val_loss: 0.5483 - val_accuracy: 0.8190\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4415 - accuracy: 0.8499 - val_loss: 0.5731 - val_accuracy: 0.8206\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4386 - accuracy: 0.8494 - val_loss: 0.7841 - val_accuracy: 0.7717\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4286 - accuracy: 0.8521 - val_loss: 0.7882 - val_accuracy: 0.7823\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4202 - accuracy: 0.8589 - val_loss: 0.5272 - val_accuracy: 0.8283\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4116 - accuracy: 0.8612 - val_loss: 0.5827 - val_accuracy: 0.8198\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.3985 - accuracy: 0.8651 - val_loss: 0.5742 - val_accuracy: 0.8354\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.3896 - accuracy: 0.8676 - val_loss: 0.7468 - val_accuracy: 0.7812\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3878 - accuracy: 0.8668 - val_loss: 0.6222 - val_accuracy: 0.8056\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.3777 - accuracy: 0.8713 - val_loss: 0.5724 - val_accuracy: 0.8229\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3691 - accuracy: 0.8735 - val_loss: 0.5827 - val_accuracy: 0.8216\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.3639 - accuracy: 0.8756 - val_loss: 0.5769 - val_accuracy: 0.8318\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.3551 - accuracy: 0.8798 - val_loss: 0.5211 - val_accuracy: 0.8335\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.3489 - accuracy: 0.8805 - val_loss: 0.4362 - val_accuracy: 0.8586\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3440 - accuracy: 0.8814 - val_loss: 0.5385 - val_accuracy: 0.8402\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3387 - accuracy: 0.8851 - val_loss: 0.6017 - val_accuracy: 0.8324\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3315 - accuracy: 0.8875 - val_loss: 0.4757 - val_accuracy: 0.8510\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3289 - accuracy: 0.8881 - val_loss: 0.5943 - val_accuracy: 0.8279\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3225 - accuracy: 0.8898 - val_loss: 0.5159 - val_accuracy: 0.8484\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3225 - accuracy: 0.8901 - val_loss: 0.4566 - val_accuracy: 0.8556\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3126 - accuracy: 0.8921 - val_loss: 0.7198 - val_accuracy: 0.8128\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3052 - accuracy: 0.8962 - val_loss: 0.5238 - val_accuracy: 0.8384\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3067 - accuracy: 0.8944 - val_loss: 0.6422 - val_accuracy: 0.8236\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.3058 - accuracy: 0.8946 - val_loss: 0.4660 - val_accuracy: 0.8568\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2935 - accuracy: 0.8994 - val_loss: 0.4944 - val_accuracy: 0.8538\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 36s 94ms/step - loss: 0.2884 - accuracy: 0.9019 - val_loss: 0.4649 - val_accuracy: 0.8603\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2862 - accuracy: 0.9026 - val_loss: 0.5007 - val_accuracy: 0.8526\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2857 - accuracy: 0.9020 - val_loss: 0.4425 - val_accuracy: 0.8675\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.2784 - accuracy: 0.9040 - val_loss: 0.4601 - val_accuracy: 0.8607\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2780 - accuracy: 0.9048 - val_loss: 0.4730 - val_accuracy: 0.8610\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2720 - accuracy: 0.9056 - val_loss: 0.4965 - val_accuracy: 0.8489\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2712 - accuracy: 0.9081 - val_loss: 0.5743 - val_accuracy: 0.8459\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2675 - accuracy: 0.9082 - val_loss: 0.4722 - val_accuracy: 0.8634\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2648 - accuracy: 0.9095 - val_loss: 0.4405 - val_accuracy: 0.8704\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2628 - accuracy: 0.9100 - val_loss: 0.5075 - val_accuracy: 0.8529\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2623 - accuracy: 0.9096 - val_loss: 0.4527 - val_accuracy: 0.8698\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.2558 - accuracy: 0.9109 - val_loss: 0.6007 - val_accuracy: 0.8407\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2497 - accuracy: 0.9145 - val_loss: 0.4639 - val_accuracy: 0.8608\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2449 - accuracy: 0.9161 - val_loss: 0.5281 - val_accuracy: 0.8530\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2483 - accuracy: 0.9139 - val_loss: 0.5014 - val_accuracy: 0.8633\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.2420 - accuracy: 0.9175 - val_loss: 0.4542 - val_accuracy: 0.8683\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.87      0.91      0.89      1000\n",
            "  automobile       0.95      0.91      0.93      1000\n",
            "        bird       0.86      0.82      0.84      1000\n",
            "         cat       0.76      0.77      0.76      1000\n",
            "        deer       0.90      0.82      0.86      1000\n",
            "         dog       0.94      0.73      0.82      1000\n",
            "        frog       0.82      0.94      0.87      1000\n",
            "       horse       0.93      0.89      0.91      1000\n",
            "        ship       0.95      0.92      0.93      1000\n",
            "       truck       0.77      0.98      0.86      1000\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n",
            "Average epoch training time: 36.901494832833606 s\n",
            "[INFO] loading CIFAR-10 dataset...\n",
            "[INFO] training network...\n",
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 96)   2688        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 96)   384         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 96)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 32)   3104        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 32, 32, 32)   27680       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 32)   128         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 32)   128         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 32, 32, 32)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 32, 32, 32)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 32, 32, 64)   0           activation_149[0][0]             \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 32, 32, 32)   2080        concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 32, 32, 48)   27696       concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 32)   128         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 32, 32, 48)   192         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 32, 32, 32)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 32, 32, 48)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 32, 32, 80)   0           activation_151[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 15, 15, 80)   57680       concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 15, 15, 80)   320         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 15, 15, 80)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 15, 15, 160)  0           activation_153[0][0]             \n",
            "                                                                 max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 15, 15, 112)  18032       concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 15, 15, 48)   69168       concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 15, 15, 112)  448         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 15, 15, 48)   192         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 15, 15, 112)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 15, 15, 48)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 15, 15, 160)  0           activation_154[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 15, 15, 96)   15456       concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 15, 15, 64)   92224       concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 15, 15, 96)   384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 15, 15, 64)   256         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 15, 15, 96)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 15, 15, 64)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 15, 15, 160)  0           activation_156[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 15, 15, 80)   12880       concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 15, 15, 80)   115280      concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 15, 15, 80)   320         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 15, 15, 80)   320         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 15, 15, 80)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 15, 15, 80)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 15, 15, 160)  0           activation_158[0][0]             \n",
            "                                                                 activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 15, 15, 48)   7728        concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 15, 15, 96)   138336      concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 15, 15, 48)   192         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 15, 15, 96)   384         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 15, 15, 48)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 15, 15, 96)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 15, 15, 144)  0           activation_160[0][0]             \n",
            "                                                                 activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 96)     124512      concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 96)     384         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 96)     0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 7, 7, 240)    0           activation_162[0][0]             \n",
            "                                                                 max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 176)    42416       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    345760      concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 176)    704         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 160)    640         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 176)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 160)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 7, 7, 336)    0           activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 176)    59312       concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    484000      concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 176)    704         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 160)    640         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 7, 7, 176)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 160)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 7, 7, 336)    0           activation_165[0][0]             \n",
            "                                                                 activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 1, 1, 336)    0           concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 336)          0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 10)           3370        flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 10)           0           dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,656,250\n",
            "Trainable params: 1,652,826\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 1.4788 - accuracy: 0.4629 - val_loss: 1.5824 - val_accuracy: 0.4146\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.1245 - accuracy: 0.6014 - val_loss: 1.2343 - val_accuracy: 0.5933\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.9675 - accuracy: 0.6599 - val_loss: 1.0902 - val_accuracy: 0.6337\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.8595 - accuracy: 0.6999 - val_loss: 0.9700 - val_accuracy: 0.6593\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.7769 - accuracy: 0.7282 - val_loss: 1.0159 - val_accuracy: 0.6605\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.7190 - accuracy: 0.7509 - val_loss: 1.0209 - val_accuracy: 0.6812\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.6650 - accuracy: 0.7687 - val_loss: 1.2243 - val_accuracy: 0.6349\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.6285 - accuracy: 0.7814 - val_loss: 1.3608 - val_accuracy: 0.6245\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.5949 - accuracy: 0.7942 - val_loss: 1.1535 - val_accuracy: 0.6768\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.5636 - accuracy: 0.8057 - val_loss: 0.7330 - val_accuracy: 0.7559\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5336 - accuracy: 0.8146 - val_loss: 0.8298 - val_accuracy: 0.7445\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5154 - accuracy: 0.8219 - val_loss: 0.9688 - val_accuracy: 0.7215\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.4998 - accuracy: 0.8260 - val_loss: 0.6325 - val_accuracy: 0.7876\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.4738 - accuracy: 0.8350 - val_loss: 0.7811 - val_accuracy: 0.7526\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4597 - accuracy: 0.8411 - val_loss: 0.6052 - val_accuracy: 0.7991\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.4402 - accuracy: 0.8493 - val_loss: 0.4910 - val_accuracy: 0.8331\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4218 - accuracy: 0.8536 - val_loss: 0.6545 - val_accuracy: 0.7867\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 0.4210 - accuracy: 0.8545 - val_loss: 0.5859 - val_accuracy: 0.8243\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.4051 - accuracy: 0.8594 - val_loss: 0.5332 - val_accuracy: 0.8292\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.3887 - accuracy: 0.8661 - val_loss: 0.5663 - val_accuracy: 0.8175\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3833 - accuracy: 0.8672 - val_loss: 0.5826 - val_accuracy: 0.8120\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3672 - accuracy: 0.8730 - val_loss: 0.5096 - val_accuracy: 0.8379\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3620 - accuracy: 0.8736 - val_loss: 0.5583 - val_accuracy: 0.8290\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3520 - accuracy: 0.8777 - val_loss: 0.5740 - val_accuracy: 0.8273\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3449 - accuracy: 0.8792 - val_loss: 0.6581 - val_accuracy: 0.8127\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3346 - accuracy: 0.8833 - val_loss: 0.5593 - val_accuracy: 0.8268\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3260 - accuracy: 0.8863 - val_loss: 0.4424 - val_accuracy: 0.8591\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3206 - accuracy: 0.8889 - val_loss: 0.5170 - val_accuracy: 0.8478\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3102 - accuracy: 0.8926 - val_loss: 0.9123 - val_accuracy: 0.7604\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3024 - accuracy: 0.8961 - val_loss: 0.6425 - val_accuracy: 0.8230\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2970 - accuracy: 0.8985 - val_loss: 0.6361 - val_accuracy: 0.8153\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2961 - accuracy: 0.8976 - val_loss: 0.4905 - val_accuracy: 0.8485\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2851 - accuracy: 0.9010 - val_loss: 0.4930 - val_accuracy: 0.8500\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2806 - accuracy: 0.9024 - val_loss: 0.5127 - val_accuracy: 0.8477\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2796 - accuracy: 0.9036 - val_loss: 0.5270 - val_accuracy: 0.8369\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2745 - accuracy: 0.9025 - val_loss: 0.5319 - val_accuracy: 0.8508\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2708 - accuracy: 0.9068 - val_loss: 0.5646 - val_accuracy: 0.8454\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2681 - accuracy: 0.9067 - val_loss: 0.5325 - val_accuracy: 0.8441\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2614 - accuracy: 0.9103 - val_loss: 0.4572 - val_accuracy: 0.8544\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2513 - accuracy: 0.9128 - val_loss: 0.6025 - val_accuracy: 0.8278\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2498 - accuracy: 0.9111 - val_loss: 0.5067 - val_accuracy: 0.8477\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2434 - accuracy: 0.9141 - val_loss: 0.4472 - val_accuracy: 0.8644\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2434 - accuracy: 0.9158 - val_loss: 0.5013 - val_accuracy: 0.8530\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2372 - accuracy: 0.9189 - val_loss: 0.5381 - val_accuracy: 0.8467\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.2334 - accuracy: 0.9192 - val_loss: 0.4763 - val_accuracy: 0.8526\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.2307 - accuracy: 0.9200 - val_loss: 0.4752 - val_accuracy: 0.8575\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2258 - accuracy: 0.9226 - val_loss: 0.5859 - val_accuracy: 0.8387\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.2211 - accuracy: 0.9226 - val_loss: 0.4492 - val_accuracy: 0.8677\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.2198 - accuracy: 0.9228 - val_loss: 0.4178 - val_accuracy: 0.8767\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.2157 - accuracy: 0.9254 - val_loss: 0.4316 - val_accuracy: 0.8676\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 39s 101ms/step - loss: 0.2153 - accuracy: 0.9253 - val_loss: 0.4643 - val_accuracy: 0.8630\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.2112 - accuracy: 0.9258 - val_loss: 0.4036 - val_accuracy: 0.8796\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 39s 101ms/step - loss: 0.2074 - accuracy: 0.9288 - val_loss: 0.4695 - val_accuracy: 0.8638\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.2080 - accuracy: 0.9274 - val_loss: 0.3928 - val_accuracy: 0.8808\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.2011 - accuracy: 0.9296 - val_loss: 0.4142 - val_accuracy: 0.8756\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.1999 - accuracy: 0.9294 - val_loss: 0.4979 - val_accuracy: 0.8659\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.1989 - accuracy: 0.9308 - val_loss: 0.5740 - val_accuracy: 0.8410\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.1963 - accuracy: 0.9331 - val_loss: 0.4008 - val_accuracy: 0.8786\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.1928 - accuracy: 0.9343 - val_loss: 0.4292 - val_accuracy: 0.8756\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.1879 - accuracy: 0.9350 - val_loss: 0.5687 - val_accuracy: 0.8431\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.83      0.90      0.87      1000\n",
            "  automobile       0.76      0.98      0.86      1000\n",
            "        bird       0.80      0.85      0.83      1000\n",
            "         cat       0.77      0.75      0.76      1000\n",
            "        deer       0.96      0.74      0.84      1000\n",
            "         dog       0.96      0.62      0.76      1000\n",
            "        frog       0.79      0.96      0.87      1000\n",
            "       horse       0.87      0.92      0.89      1000\n",
            "        ship       0.99      0.77      0.87      1000\n",
            "       truck       0.84      0.92      0.88      1000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.86      0.84      0.84     10000\n",
            "weighted avg       0.86      0.84      0.84     10000\n",
            "\n",
            "Average epoch training time: 38.34396126667659 s\n",
            "[INFO] loading CIFAR-10 dataset...\n",
            "[INFO] training network...\n",
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 32, 32, 96)   411         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 32, 32, 96)   384         separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 32, 32, 96)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 32, 32, 32)   3200        activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 32, 32, 32)   3968        activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 32, 32, 32)   128         separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 32, 32, 32)   128         separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 32, 32, 32)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 32, 32, 32)   0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 32, 32, 64)   0           activation_169[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 32, 32, 32)   2144        concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 32, 32, 48)   3696        concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 32, 32, 32)   128         separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 32, 32, 48)   192         separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 32, 32, 32)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 32, 32, 48)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 32, 32, 80)   0           activation_171[0][0]             \n",
            "                                                                 activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 15, 15, 80)   7200        concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 15, 15, 80)   320         separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 15, 15, 80)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 15, 15, 160)  0           activation_173[0][0]             \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 15, 15, 112)  18192       concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 15, 15, 48)   9168        concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 15, 15, 112)  448         separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 15, 15, 48)   192         separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 15, 15, 112)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 15, 15, 48)   0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 15, 15, 160)  0           activation_174[0][0]             \n",
            "                                                                 activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 15, 15, 96)   15616       concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 15, 15, 64)   11744       concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 15, 15, 96)   384         separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 15, 15, 64)   256         separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 15, 15, 96)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 15, 15, 64)   0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 15, 15, 160)  0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 15, 15, 80)   13040       concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 15, 15, 80)   14320       concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 15, 15, 80)   320         separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 15, 15, 80)   320         separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 15, 15, 80)   0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 15, 15, 80)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 15, 15, 160)  0           activation_178[0][0]             \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 15, 15, 48)   7888        concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 15, 15, 96)   16896       concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 15, 15, 48)   192         separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 15, 15, 96)   384         separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 15, 15, 48)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 15, 15, 96)   0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 15, 15, 144)  0           activation_180[0][0]             \n",
            "                                                                 activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 7, 7, 96)     15216       concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 7, 7, 96)     384         separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 7, 7, 96)     0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 7, 7, 240)    0           activation_182[0][0]             \n",
            "                                                                 max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 7, 7, 176)    42656       concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 7, 7, 160)    40720       concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 7, 7, 176)    704         separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 7, 7, 160)    640         separable_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 7, 7, 176)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 7, 7, 160)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 7, 7, 336)    0           activation_183[0][0]             \n",
            "                                                                 activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 7, 7, 176)    59648       concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_37 (SeparableC (None, 7, 7, 160)    56944       concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 7, 7, 176)    704         separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 7, 7, 160)    640         separable_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 7, 7, 176)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 7, 7, 160)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 7, 7, 336)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 336)    0           concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1, 1, 336)    0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 336)          0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 10)           3370        flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 10)           0           dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 352,885\n",
            "Trainable params: 349,461\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "390/390 [==============================] - 39s 101ms/step - loss: 1.6610 - accuracy: 0.3872 - val_loss: 2.5367 - val_accuracy: 0.1000\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.3015 - accuracy: 0.5330 - val_loss: 1.9955 - val_accuracy: 0.4401\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.1601 - accuracy: 0.5855 - val_loss: 1.8562 - val_accuracy: 0.4854\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 1.0626 - accuracy: 0.6248 - val_loss: 1.3487 - val_accuracy: 0.5482\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.9972 - accuracy: 0.6514 - val_loss: 1.1222 - val_accuracy: 0.6168\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.9417 - accuracy: 0.6702 - val_loss: 1.1228 - val_accuracy: 0.6198\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.8935 - accuracy: 0.6892 - val_loss: 1.2910 - val_accuracy: 0.5976\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.8612 - accuracy: 0.6988 - val_loss: 1.2709 - val_accuracy: 0.5865\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.8275 - accuracy: 0.7134 - val_loss: 0.8187 - val_accuracy: 0.7245\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.7999 - accuracy: 0.7248 - val_loss: 1.1002 - val_accuracy: 0.6465\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.7702 - accuracy: 0.7349 - val_loss: 0.9094 - val_accuracy: 0.7100\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.7453 - accuracy: 0.7421 - val_loss: 0.9897 - val_accuracy: 0.6912\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.7265 - accuracy: 0.7521 - val_loss: 0.7367 - val_accuracy: 0.7562\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.7055 - accuracy: 0.7561 - val_loss: 1.0398 - val_accuracy: 0.6899\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.6925 - accuracy: 0.7624 - val_loss: 1.0484 - val_accuracy: 0.6675\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 0.6787 - accuracy: 0.7675 - val_loss: 1.0459 - val_accuracy: 0.7083\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.6647 - accuracy: 0.7712 - val_loss: 0.8341 - val_accuracy: 0.7497\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 0.6438 - accuracy: 0.7809 - val_loss: 0.9883 - val_accuracy: 0.7082\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.6307 - accuracy: 0.7832 - val_loss: 0.7738 - val_accuracy: 0.7462\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 0.6210 - accuracy: 0.7881 - val_loss: 0.6828 - val_accuracy: 0.7689\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.6100 - accuracy: 0.7910 - val_loss: 0.6880 - val_accuracy: 0.7796\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.6031 - accuracy: 0.7937 - val_loss: 0.6794 - val_accuracy: 0.7915\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.5913 - accuracy: 0.7977 - val_loss: 0.6189 - val_accuracy: 0.7929\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5823 - accuracy: 0.8008 - val_loss: 0.5914 - val_accuracy: 0.8015\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5792 - accuracy: 0.8042 - val_loss: 0.7104 - val_accuracy: 0.7781\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5689 - accuracy: 0.8058 - val_loss: 0.7164 - val_accuracy: 0.7763\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5562 - accuracy: 0.8105 - val_loss: 0.6032 - val_accuracy: 0.8045\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5528 - accuracy: 0.8104 - val_loss: 0.5798 - val_accuracy: 0.8058\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5450 - accuracy: 0.8137 - val_loss: 0.7388 - val_accuracy: 0.7639\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.5387 - accuracy: 0.8167 - val_loss: 0.7368 - val_accuracy: 0.7784\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.5303 - accuracy: 0.8184 - val_loss: 0.7432 - val_accuracy: 0.7754\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.5224 - accuracy: 0.8207 - val_loss: 0.5733 - val_accuracy: 0.8087\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.5213 - accuracy: 0.8224 - val_loss: 0.8108 - val_accuracy: 0.7709\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.5136 - accuracy: 0.8235 - val_loss: 0.6249 - val_accuracy: 0.8061\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.5083 - accuracy: 0.8268 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.5024 - accuracy: 0.8279 - val_loss: 0.7246 - val_accuracy: 0.7761\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4951 - accuracy: 0.8309 - val_loss: 0.5315 - val_accuracy: 0.8270\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.4956 - accuracy: 0.8289 - val_loss: 0.6588 - val_accuracy: 0.7957\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.4879 - accuracy: 0.8334 - val_loss: 0.4960 - val_accuracy: 0.8350\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4908 - accuracy: 0.8320 - val_loss: 0.6957 - val_accuracy: 0.7950\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.4792 - accuracy: 0.8347 - val_loss: 0.6637 - val_accuracy: 0.7998\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4845 - accuracy: 0.8342 - val_loss: 0.5053 - val_accuracy: 0.8347\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4685 - accuracy: 0.8400 - val_loss: 0.7016 - val_accuracy: 0.7859\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4685 - accuracy: 0.8387 - val_loss: 0.4917 - val_accuracy: 0.8426\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4645 - accuracy: 0.8405 - val_loss: 0.5824 - val_accuracy: 0.8197\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4595 - accuracy: 0.8426 - val_loss: 0.5692 - val_accuracy: 0.8271\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4622 - accuracy: 0.8418 - val_loss: 0.5548 - val_accuracy: 0.8230\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4543 - accuracy: 0.8436 - val_loss: 0.6311 - val_accuracy: 0.8050\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4502 - accuracy: 0.8454 - val_loss: 0.5862 - val_accuracy: 0.8146\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4489 - accuracy: 0.8490 - val_loss: 0.5773 - val_accuracy: 0.8103\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4412 - accuracy: 0.8493 - val_loss: 0.5296 - val_accuracy: 0.8300\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.4406 - accuracy: 0.8490 - val_loss: 0.7181 - val_accuracy: 0.7977\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4401 - accuracy: 0.8493 - val_loss: 0.6099 - val_accuracy: 0.8097\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4336 - accuracy: 0.8511 - val_loss: 0.6922 - val_accuracy: 0.8112\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.4335 - accuracy: 0.8521 - val_loss: 0.4936 - val_accuracy: 0.8433\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.4280 - accuracy: 0.8526 - val_loss: 0.5993 - val_accuracy: 0.8167\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4261 - accuracy: 0.8546 - val_loss: 0.5923 - val_accuracy: 0.8220\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.4242 - accuracy: 0.8545 - val_loss: 0.5183 - val_accuracy: 0.8356\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4184 - accuracy: 0.8578 - val_loss: 0.6858 - val_accuracy: 0.8013\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.4213 - accuracy: 0.8561 - val_loss: 0.5276 - val_accuracy: 0.8324\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.93      0.73      0.82      1000\n",
            "  automobile       0.82      0.98      0.89      1000\n",
            "        bird       0.91      0.63      0.74      1000\n",
            "         cat       0.68      0.78      0.73      1000\n",
            "        deer       0.82      0.82      0.82      1000\n",
            "         dog       0.84      0.77      0.80      1000\n",
            "        frog       0.87      0.87      0.87      1000\n",
            "       horse       0.80      0.92      0.85      1000\n",
            "        ship       0.86      0.93      0.90      1000\n",
            "       truck       0.87      0.90      0.89      1000\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.84      0.83      0.83     10000\n",
            "weighted avg       0.84      0.83      0.83     10000\n",
            "\n",
            "Average epoch training time: 37.568974979718526 s\n",
            "[INFO] loading CIFAR-10 dataset...\n",
            "[INFO] training network...\n",
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 32, 32, 96)   2688        input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 32, 32, 96)   384         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 32, 32, 96)   0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 32, 32, 26)   2522        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 32, 32, 25)   21625       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 32, 32, 13)   31213       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 32, 32, 26)   104         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 32, 32, 25)   100         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 32, 32, 13)   52          conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 32, 32, 26)   0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 32, 32, 25)   0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 32, 32, 13)   0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 32, 32, 64)   0           activation_189[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "                                                                 activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 32, 32, 26)   1690        concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 32, 32, 38)   21926       concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 32, 32, 16)   25616       concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 32, 32, 26)   104         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 32, 32, 38)   152         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 32, 32, 16)   64          conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 32, 32, 26)   0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 32, 32, 38)   0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 32, 32, 16)   0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 32, 32, 80)   0           activation_192[0][0]             \n",
            "                                                                 activation_193[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 15, 15, 80)   57680       concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 15, 15, 80)   320         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 15, 15, 80)   0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 15, 15, 160)  0           activation_195[0][0]             \n",
            "                                                                 max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 15, 15, 90)   14490       concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 15, 15, 38)   54758       concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 15, 15, 32)   128032      concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 15, 15, 90)   360         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 15, 15, 38)   152         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 15, 15, 32)   128         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 15, 15, 90)   0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 15, 15, 38)   0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 15, 15, 32)   0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 15, 15, 160)  0           activation_196[0][0]             \n",
            "                                                                 activation_197[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 15, 15, 77)   12397       concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 15, 15, 51)   73491       concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 15, 15, 32)   128032      concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 15, 15, 77)   308         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 15, 15, 51)   204         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 15, 15, 32)   128         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 15, 15, 77)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 15, 15, 51)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 15, 15, 32)   0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 15, 15, 160)  0           activation_199[0][0]             \n",
            "                                                                 activation_200[0][0]             \n",
            "                                                                 activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 15, 15, 64)   10304       concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 15, 15, 64)   92224       concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 15, 15, 32)   128032      concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 15, 15, 64)   256         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 15, 15, 64)   256         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 15, 15, 32)   128         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 15, 15, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 15, 15, 64)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 15, 15, 32)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 15, 15, 160)  0           activation_202[0][0]             \n",
            "                                                                 activation_203[0][0]             \n",
            "                                                                 activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 15, 15, 38)   6118        concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 15, 15, 77)   110957      concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 15, 15, 29)   116029      concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 15, 15, 38)   152         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 15, 15, 77)   308         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 15, 15, 29)   116         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 15, 15, 38)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 15, 15, 77)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 15, 15, 29)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 15, 15, 144)  0           activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "                                                                 activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 96)     124512      concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 7, 7, 96)     384         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 7, 7, 96)     0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 7, 7, 240)    0           activation_208[0][0]             \n",
            "                                                                 max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 141)    33981       concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 128)    276608      concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 67)     402067      concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 7, 7, 141)    564         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 7, 7, 128)    512         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 7, 7, 67)     268         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 7, 7, 141)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 7, 7, 128)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 7, 7, 67)     0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 7, 7, 336)    0           activation_209[0][0]             \n",
            "                                                                 activation_210[0][0]             \n",
            "                                                                 activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 7, 7, 141)    47517       concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 128)    387200      concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 67)     562867      concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 7, 7, 141)    564         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 7, 7, 128)    512         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 7, 7, 67)     268         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 7, 7, 141)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 7, 7, 128)    0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 7, 7, 67)     0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 7, 7, 336)    0           activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "                                                                 activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 336)    0           concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1, 1, 336)    0           average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 336)          0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           3370        flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 10)           0           dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,884,794\n",
            "Trainable params: 2,881,370\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "390/390 [==============================] - 54s 138ms/step - loss: 1.5724 - accuracy: 0.4272 - val_loss: 1.9568 - val_accuracy: 0.3214\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 1.1711 - accuracy: 0.5827 - val_loss: 1.4573 - val_accuracy: 0.5051\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.9917 - accuracy: 0.6520 - val_loss: 1.2684 - val_accuracy: 0.5788\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.8694 - accuracy: 0.6961 - val_loss: 1.0721 - val_accuracy: 0.6425\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.7839 - accuracy: 0.7287 - val_loss: 1.5810 - val_accuracy: 0.5855\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.7200 - accuracy: 0.7517 - val_loss: 0.8386 - val_accuracy: 0.7136\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.6819 - accuracy: 0.7647 - val_loss: 0.9200 - val_accuracy: 0.7009\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.6381 - accuracy: 0.7819 - val_loss: 0.6051 - val_accuracy: 0.7944\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.5923 - accuracy: 0.7953 - val_loss: 0.6040 - val_accuracy: 0.7967\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.5686 - accuracy: 0.8037 - val_loss: 0.7477 - val_accuracy: 0.7607\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.5413 - accuracy: 0.8145 - val_loss: 0.5977 - val_accuracy: 0.8023\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.5172 - accuracy: 0.8227 - val_loss: 0.6433 - val_accuracy: 0.7934\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.4983 - accuracy: 0.8282 - val_loss: 0.6105 - val_accuracy: 0.7890\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4756 - accuracy: 0.8369 - val_loss: 0.6630 - val_accuracy: 0.7894\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4639 - accuracy: 0.8398 - val_loss: 0.6327 - val_accuracy: 0.8011\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4502 - accuracy: 0.8454 - val_loss: 0.7673 - val_accuracy: 0.7714\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4310 - accuracy: 0.8528 - val_loss: 0.6116 - val_accuracy: 0.8096\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4218 - accuracy: 0.8557 - val_loss: 0.8035 - val_accuracy: 0.7632\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.4066 - accuracy: 0.8596 - val_loss: 0.6267 - val_accuracy: 0.8059\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3932 - accuracy: 0.8644 - val_loss: 0.6024 - val_accuracy: 0.8107\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3819 - accuracy: 0.8679 - val_loss: 0.7281 - val_accuracy: 0.7928\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3774 - accuracy: 0.8720 - val_loss: 0.5635 - val_accuracy: 0.8275\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.3626 - accuracy: 0.8757 - val_loss: 0.6221 - val_accuracy: 0.8101\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.3518 - accuracy: 0.8797 - val_loss: 0.5083 - val_accuracy: 0.8405\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3394 - accuracy: 0.8839 - val_loss: 0.5221 - val_accuracy: 0.8312\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3377 - accuracy: 0.8848 - val_loss: 0.4501 - val_accuracy: 0.8512\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.3313 - accuracy: 0.8865 - val_loss: 0.4095 - val_accuracy: 0.8659\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3245 - accuracy: 0.8879 - val_loss: 0.5337 - val_accuracy: 0.8387\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3149 - accuracy: 0.8904 - val_loss: 0.5758 - val_accuracy: 0.8294\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.3074 - accuracy: 0.8929 - val_loss: 0.4338 - val_accuracy: 0.8604\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.2970 - accuracy: 0.8978 - val_loss: 0.5487 - val_accuracy: 0.8333\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2925 - accuracy: 0.8996 - val_loss: 0.4479 - val_accuracy: 0.8588\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.2912 - accuracy: 0.8989 - val_loss: 0.4764 - val_accuracy: 0.8544\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2864 - accuracy: 0.9013 - val_loss: 0.5177 - val_accuracy: 0.8431\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.2786 - accuracy: 0.9030 - val_loss: 0.4806 - val_accuracy: 0.8526\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2758 - accuracy: 0.9046 - val_loss: 0.4408 - val_accuracy: 0.8657\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2684 - accuracy: 0.9072 - val_loss: 0.3996 - val_accuracy: 0.8707\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2612 - accuracy: 0.9104 - val_loss: 0.4588 - val_accuracy: 0.8591\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2602 - accuracy: 0.9103 - val_loss: 0.3966 - val_accuracy: 0.8708\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2554 - accuracy: 0.9120 - val_loss: 0.4814 - val_accuracy: 0.8564\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2468 - accuracy: 0.9155 - val_loss: 0.4487 - val_accuracy: 0.8656\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2460 - accuracy: 0.9164 - val_loss: 0.3870 - val_accuracy: 0.8776\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2422 - accuracy: 0.9174 - val_loss: 0.3766 - val_accuracy: 0.8828\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2363 - accuracy: 0.9188 - val_loss: 0.5092 - val_accuracy: 0.8563\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2305 - accuracy: 0.9209 - val_loss: 0.4749 - val_accuracy: 0.8589\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2283 - accuracy: 0.9203 - val_loss: 0.3767 - val_accuracy: 0.8786\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.2248 - accuracy: 0.9225 - val_loss: 0.4955 - val_accuracy: 0.8557\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2220 - accuracy: 0.9245 - val_loss: 0.4464 - val_accuracy: 0.8663\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2213 - accuracy: 0.9233 - val_loss: 0.4676 - val_accuracy: 0.8611\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2176 - accuracy: 0.9252 - val_loss: 0.5183 - val_accuracy: 0.8513\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 52s 133ms/step - loss: 0.2159 - accuracy: 0.9260 - val_loss: 0.4594 - val_accuracy: 0.8647\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2108 - accuracy: 0.9269 - val_loss: 0.4679 - val_accuracy: 0.8684\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2075 - accuracy: 0.9283 - val_loss: 0.4949 - val_accuracy: 0.8537\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1995 - accuracy: 0.9321 - val_loss: 0.3707 - val_accuracy: 0.8873\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1981 - accuracy: 0.9307 - val_loss: 0.4153 - val_accuracy: 0.8809\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.2006 - accuracy: 0.9294 - val_loss: 0.4250 - val_accuracy: 0.8798\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1908 - accuracy: 0.9342 - val_loss: 0.4035 - val_accuracy: 0.8821\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1937 - accuracy: 0.9330 - val_loss: 0.4573 - val_accuracy: 0.8725\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1887 - accuracy: 0.9348 - val_loss: 0.4534 - val_accuracy: 0.8708\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 52s 134ms/step - loss: 0.1835 - accuracy: 0.9367 - val_loss: 0.4321 - val_accuracy: 0.8788\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.83      0.95      0.89      1000\n",
            "  automobile       0.86      0.98      0.92      1000\n",
            "        bird       0.94      0.77      0.85      1000\n",
            "         cat       0.85      0.75      0.80      1000\n",
            "        deer       0.80      0.93      0.86      1000\n",
            "         dog       0.91      0.77      0.83      1000\n",
            "        frog       0.84      0.97      0.90      1000\n",
            "       horse       0.89      0.92      0.91      1000\n",
            "        ship       0.97      0.86      0.91      1000\n",
            "       truck       0.94      0.88      0.91      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Average epoch training time: 52.38947483698527 s\n",
            "[INFO] loading CIFAR-10 dataset...\n",
            "[INFO] training network...\n",
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 96)   2688        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 32, 32, 96)   384         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 32, 32, 96)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 32)   3104        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 32)   27680       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 32, 32, 32)   128         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 32, 32, 32)   128         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 32, 32, 32)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 32, 32, 32)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 64)   0           activation_217[0][0]             \n",
            "                                                                 activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 32)   2080        concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 48)   27696       concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 32, 32, 32)   128         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 32, 32, 48)   192         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 32, 32, 32)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 32, 32, 48)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 80)   0           activation_219[0][0]             \n",
            "                                                                 activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 15, 15, 80)   57680       concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 15, 15, 80)   320         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 15, 15, 80)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 15, 15, 160)  0           activation_221[0][0]             \n",
            "                                                                 max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 15, 15, 112)  18032       concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 15, 15, 48)   69168       concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 15, 15, 112)  448         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 15, 15, 48)   192         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 15, 15, 112)  0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 15, 15, 48)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 15, 15, 160)  0           activation_222[0][0]             \n",
            "                                                                 activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 15, 15, 96)   15456       concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 15, 15, 64)   92224       concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 15, 15, 96)   384         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 15, 15, 64)   256         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 15, 15, 96)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 15, 15, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 15, 15, 160)  0           activation_224[0][0]             \n",
            "                                                                 activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 15, 15, 80)   12880       concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 15, 15, 80)   115280      concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 15, 15, 80)   320         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 15, 15, 80)   320         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 15, 15, 80)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 15, 15, 80)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 15, 15, 160)  0           activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 15, 15, 48)   7728        concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 15, 15, 96)   138336      concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 15, 15, 48)   192         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 15, 15, 96)   384         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 15, 15, 48)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 15, 15, 96)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 15, 15, 144)  0           activation_228[0][0]             \n",
            "                                                                 activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 7, 7, 96)     124512      concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 7, 7, 96)     384         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 96)     0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 7, 7, 240)    0           activation_230[0][0]             \n",
            "                                                                 max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 7, 7, 176)    42416       concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 7, 7, 160)    345760      concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 7, 7, 176)    704         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 7, 7, 160)    640         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 176)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 7, 7, 336)    0           activation_231[0][0]             \n",
            "                                                                 activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 7, 7, 176)    59312       concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 7, 7, 160)    484000      concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 7, 7, 176)    704         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 7, 7, 160)    640         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 176)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 7, 7, 336)    0           activation_233[0][0]             \n",
            "                                                                 activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 336)          0           concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 336)          0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 336)          0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 10)           3370        flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 10)           0           dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,656,250\n",
            "Trainable params: 1,652,826\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 1.6186 - accuracy: 0.4082 - val_loss: 2.0407 - val_accuracy: 0.3316\n",
            "Epoch 2/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.2400 - accuracy: 0.5567 - val_loss: 2.4252 - val_accuracy: 0.4127\n",
            "Epoch 3/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.0661 - accuracy: 0.6228 - val_loss: 1.3382 - val_accuracy: 0.5761\n",
            "Epoch 4/60\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 0.9548 - accuracy: 0.6654 - val_loss: 1.0849 - val_accuracy: 0.6371\n",
            "Epoch 5/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.8732 - accuracy: 0.6956 - val_loss: 0.9161 - val_accuracy: 0.6908\n",
            "Epoch 6/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.8107 - accuracy: 0.7210 - val_loss: 1.0986 - val_accuracy: 0.6655\n",
            "Epoch 7/60\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 0.7595 - accuracy: 0.7380 - val_loss: 0.7918 - val_accuracy: 0.7303\n",
            "Epoch 8/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.7195 - accuracy: 0.7531 - val_loss: 1.0711 - val_accuracy: 0.6426\n",
            "Epoch 9/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.6830 - accuracy: 0.7650 - val_loss: 0.7950 - val_accuracy: 0.7438\n",
            "Epoch 10/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.6513 - accuracy: 0.7785 - val_loss: 0.8457 - val_accuracy: 0.7219\n",
            "Epoch 11/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.6237 - accuracy: 0.7853 - val_loss: 0.9825 - val_accuracy: 0.7064\n",
            "Epoch 12/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5947 - accuracy: 0.7982 - val_loss: 0.7017 - val_accuracy: 0.7807\n",
            "Epoch 13/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5790 - accuracy: 0.8011 - val_loss: 0.8436 - val_accuracy: 0.7395\n",
            "Epoch 14/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5523 - accuracy: 0.8131 - val_loss: 0.5628 - val_accuracy: 0.8154\n",
            "Epoch 15/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5380 - accuracy: 0.8163 - val_loss: 0.6672 - val_accuracy: 0.7858\n",
            "Epoch 16/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5138 - accuracy: 0.8219 - val_loss: 0.6849 - val_accuracy: 0.7752\n",
            "Epoch 17/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5026 - accuracy: 0.8270 - val_loss: 0.6474 - val_accuracy: 0.7931\n",
            "Epoch 18/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4888 - accuracy: 0.8351 - val_loss: 0.7018 - val_accuracy: 0.7869\n",
            "Epoch 19/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.4767 - accuracy: 0.8363 - val_loss: 0.6639 - val_accuracy: 0.7976\n",
            "Epoch 20/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.4635 - accuracy: 0.8417 - val_loss: 0.5980 - val_accuracy: 0.8134\n",
            "Epoch 21/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4526 - accuracy: 0.8439 - val_loss: 0.7387 - val_accuracy: 0.7763\n",
            "Epoch 22/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4394 - accuracy: 0.8495 - val_loss: 0.5734 - val_accuracy: 0.8174\n",
            "Epoch 23/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4302 - accuracy: 0.8540 - val_loss: 0.6515 - val_accuracy: 0.8006\n",
            "Epoch 24/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4242 - accuracy: 0.8554 - val_loss: 0.6367 - val_accuracy: 0.8132\n",
            "Epoch 25/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4111 - accuracy: 0.8593 - val_loss: 0.6112 - val_accuracy: 0.8167\n",
            "Epoch 26/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4034 - accuracy: 0.8624 - val_loss: 0.5493 - val_accuracy: 0.8291\n",
            "Epoch 27/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3994 - accuracy: 0.8642 - val_loss: 0.4691 - val_accuracy: 0.8489\n",
            "Epoch 28/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3817 - accuracy: 0.8712 - val_loss: 0.4715 - val_accuracy: 0.8519\n",
            "Epoch 29/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3807 - accuracy: 0.8696 - val_loss: 0.5366 - val_accuracy: 0.8346\n",
            "Epoch 30/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3763 - accuracy: 0.8708 - val_loss: 0.5638 - val_accuracy: 0.8262\n",
            "Epoch 31/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.3702 - accuracy: 0.8723 - val_loss: 0.7123 - val_accuracy: 0.7925\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3591 - accuracy: 0.8772 - val_loss: 0.4562 - val_accuracy: 0.8565\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3485 - accuracy: 0.8792 - val_loss: 0.4993 - val_accuracy: 0.8436\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.3475 - accuracy: 0.8812 - val_loss: 0.4447 - val_accuracy: 0.8579\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3408 - accuracy: 0.8827 - val_loss: 0.4175 - val_accuracy: 0.8627\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3316 - accuracy: 0.8864 - val_loss: 0.6471 - val_accuracy: 0.8155\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3355 - accuracy: 0.8841 - val_loss: 0.6952 - val_accuracy: 0.8112\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3238 - accuracy: 0.8879 - val_loss: 0.6693 - val_accuracy: 0.8113\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3249 - accuracy: 0.8886 - val_loss: 0.4349 - val_accuracy: 0.8585\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.3109 - accuracy: 0.8931 - val_loss: 0.5721 - val_accuracy: 0.8359\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3099 - accuracy: 0.8934 - val_loss: 0.4341 - val_accuracy: 0.8686\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.3125 - accuracy: 0.8926 - val_loss: 0.5018 - val_accuracy: 0.8485\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.3032 - accuracy: 0.8953 - val_loss: 0.4787 - val_accuracy: 0.8581\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2978 - accuracy: 0.8978 - val_loss: 0.5735 - val_accuracy: 0.8315\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.2945 - accuracy: 0.8999 - val_loss: 0.4494 - val_accuracy: 0.8610\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2844 - accuracy: 0.9025 - val_loss: 0.5297 - val_accuracy: 0.8480\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2863 - accuracy: 0.9018 - val_loss: 0.6977 - val_accuracy: 0.8124\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2848 - accuracy: 0.9018 - val_loss: 0.4984 - val_accuracy: 0.8556\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 39s 101ms/step - loss: 0.2756 - accuracy: 0.9046 - val_loss: 0.4748 - val_accuracy: 0.8601\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2711 - accuracy: 0.9058 - val_loss: 0.6402 - val_accuracy: 0.8281\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2774 - accuracy: 0.9051 - val_loss: 0.5137 - val_accuracy: 0.8513\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2701 - accuracy: 0.9066 - val_loss: 0.4305 - val_accuracy: 0.8704\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2677 - accuracy: 0.9089 - val_loss: 0.5038 - val_accuracy: 0.8569\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.2648 - accuracy: 0.9092 - val_loss: 0.4793 - val_accuracy: 0.8601\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2607 - accuracy: 0.9120 - val_loss: 0.4320 - val_accuracy: 0.8691\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2585 - accuracy: 0.9114 - val_loss: 0.5626 - val_accuracy: 0.8496\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.2579 - accuracy: 0.9116 - val_loss: 0.4478 - val_accuracy: 0.8692\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2510 - accuracy: 0.9137 - val_loss: 0.4600 - val_accuracy: 0.8719\n",
            "Epoch 59/60\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.2450 - accuracy: 0.9153 - val_loss: 0.4566 - val_accuracy: 0.8690\n",
            "Epoch 60/60\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 0.2446 - accuracy: 0.9149 - val_loss: 0.5377 - val_accuracy: 0.8614\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.91      0.84      0.88      1000\n",
            "  automobile       0.77      0.99      0.87      1000\n",
            "        bird       0.87      0.80      0.83      1000\n",
            "         cat       0.84      0.72      0.77      1000\n",
            "        deer       0.90      0.82      0.86      1000\n",
            "         dog       0.87      0.80      0.83      1000\n",
            "        frog       0.79      0.95      0.87      1000\n",
            "       horse       0.90      0.90      0.90      1000\n",
            "        ship       0.94      0.89      0.92      1000\n",
            "       truck       0.88      0.89      0.89      1000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "Average epoch training time: 38.03543717463811 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkx4SF0x3jSp"
      },
      "source": [
        "# Zmiana rozmiaru obrazu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUdac3zB3xiL"
      },
      "source": [
        "import random\n",
        "import cv2\n",
        "import tensorflow.keras.models as models"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9a9BDvO3WBg"
      },
      "source": [
        "def get_images(n):\n",
        "    random.seed(100)\n",
        "    (train_images, train_labels), _ = cifar10.load_data()\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    chosen_images = []\n",
        "    chosen_labels = []\n",
        "    train_images = train_images.astype(\"float32\") / 255.0\n",
        "\n",
        "    for i in range(0, n):\n",
        "        index = random.randrange(0, len(train_images))\n",
        "        chosen_image = train_images[index]\n",
        "        chosen_images.append(chosen_image)\n",
        "        chosen_labels.append(class_names[train_labels[index][0]])\n",
        "\n",
        "    return chosen_images, chosen_labels"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "XNYipJGJ3iN-",
        "outputId": "98ada70e-b877-4793-fbb6-192e86eb9408"
      },
      "source": [
        "chosen_images, chosen_labels = get_images(3)\n",
        "resized_images = []\n",
        "for image in chosen_images:\n",
        "    resized_images.append(cv2.resize(image, (36, 28)))\n",
        "\n",
        "for i in range(0, 3):\n",
        "    plt.figure()\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(resized_images[i])\n",
        "    plt.xlabel(chosen_labels[i])\n",
        "    plt.savefig(\"cifar-{}.png\".format(i))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDTBXz9aGaiI",
        "outputId": "a802c2d0-936b-4700-caeb-4d4bee9960fc"
      },
      "source": [
        "model_name = \"drive/MyDrive/mro/miniinception_5\"\n",
        "model = models.load_model(model_name)\n",
        "for image in resized_images:\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pred_vec = model.predict(image, batch_size=1)\n",
        "    prediction = np.argmax(pred_vec)\n",
        "    print(LABEL_NAMES[prediction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"miniinceptionnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 96)   2688        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 32, 32, 96)   384         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 32, 32, 96)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 32)   3104        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 32)   27680       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 32, 32, 32)   128         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 32, 32, 32)   128         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 32, 32, 32)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 32, 32, 32)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 64)   0           activation_217[0][0]             \n",
            "                                                                 activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 32)   2080        concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 48)   27696       concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 32, 32, 32)   128         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 32, 32, 48)   192         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 32, 32, 32)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 32, 32, 48)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 80)   0           activation_219[0][0]             \n",
            "                                                                 activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 15, 15, 80)   57680       concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 15, 15, 80)   320         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 15, 15, 80)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 15, 15, 80)   0           concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 15, 15, 160)  0           activation_221[0][0]             \n",
            "                                                                 max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 15, 15, 112)  18032       concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 15, 15, 48)   69168       concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 15, 15, 112)  448         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 15, 15, 48)   192         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 15, 15, 112)  0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 15, 15, 48)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 15, 15, 160)  0           activation_222[0][0]             \n",
            "                                                                 activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 15, 15, 96)   15456       concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 15, 15, 64)   92224       concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 15, 15, 96)   384         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 15, 15, 64)   256         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 15, 15, 96)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 15, 15, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 15, 15, 160)  0           activation_224[0][0]             \n",
            "                                                                 activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 15, 15, 80)   12880       concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 15, 15, 80)   115280      concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 15, 15, 80)   320         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 15, 15, 80)   320         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 15, 15, 80)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 15, 15, 80)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 15, 15, 160)  0           activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 15, 15, 48)   7728        concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 15, 15, 96)   138336      concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 15, 15, 48)   192         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 15, 15, 96)   384         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 15, 15, 48)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 15, 15, 96)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 15, 15, 144)  0           activation_228[0][0]             \n",
            "                                                                 activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 7, 7, 96)     124512      concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 7, 7, 96)     384         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 96)     0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 7, 7, 144)    0           concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 7, 7, 240)    0           activation_230[0][0]             \n",
            "                                                                 max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 7, 7, 176)    42416       concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 7, 7, 160)    345760      concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 7, 7, 176)    704         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 7, 7, 160)    640         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 176)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 7, 7, 336)    0           activation_231[0][0]             \n",
            "                                                                 activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 7, 7, 176)    59312       concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 7, 7, 160)    484000      concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 7, 7, 176)    704         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 7, 7, 160)    640         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 176)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 7, 7, 336)    0           activation_233[0][0]             \n",
            "                                                                 activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 336)          0           concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 336)          0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 336)          0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 10)           3370        flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 10)           0           dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,656,250\n",
            "Trainable params: 1,652,826\n",
            "Non-trainable params: 3,424\n",
            "__________________________________________________________________________________________________\n",
            "deer\n",
            "dog\n",
            "bird\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDUv0r7oJf84"
      },
      "source": [
        "# Heatmapy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAM2VBtbJvIQ"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "import tensorflow.keras.models as models\n",
        "from skimage.transform import resize\n",
        "import random"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNDYwYL9LisQ"
      },
      "source": [
        "def get_CAM(model, image, weights):\n",
        "    analysed = np.expand_dims(image, axis=0)\n",
        "    gap_input, prediction_vector = model.predict(analysed)\n",
        "    gap_input = np.squeeze(gap_input)\n",
        "    prediction = np.argmax(prediction_vector)\n",
        "\n",
        "    scale_factor = 32 / 7\n",
        "    matrix_for_multiplication = scipy.ndimage.zoom(gap_input, (scale_factor, scale_factor, 1), order=1)\n",
        "    weights_for_predicted = weights[:, prediction]\n",
        "    final_output = np.dot(matrix_for_multiplication.reshape((32 * 32, 336)), weights_for_predicted).reshape(32, 32)\n",
        "    return final_output, prediction"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF0R1zwaQ7ZU"
      },
      "source": [
        "model_name = \"drive/MyDrive/mro/miniinception_5\"\n",
        "model = models.load_model(model_name)\n",
        "weights = model.layers[-2].get_weights()[0]\n",
        "model_for_heatmap = models.Model(inputs=model.input, outputs=(model.layers[-6].output, model.layers[-1].output))\n",
        "images, labels = get_images(3)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "Y4my4T8DJbU0",
        "outputId": "7f0a1a1c-3faf-4041-bbef-dbad35970909"
      },
      "source": [
        "for i in range(len(images)):\n",
        "    cam, prediction = get_CAM(model_for_heatmap, images[i], weights)\n",
        "    label = LABEL_NAMES[prediction]\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(images[i], alpha=0.5)\n",
        "    plt.imshow(cam, alpha=0.5)\n",
        "    plt.xlabel(label)\n",
        "    plt.savefig(\"heatmap-{}.png\".format(i))\n",
        "    plt.show()\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}